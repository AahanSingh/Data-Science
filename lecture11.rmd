
---
title: Lecture 11 - Lab 10 discussion, plyr
author: 94-842
date: October 4, 2016
output: 
  html_document:
    toc: true
    toc_depth: 5
---

```{r}
library(plyr)
library(ggplot2)
library(knitr)
library(MASS)

options(scipen = 4)
```

### Lab 10: A first look at the nlsy data

Let's start by loading the data for the final project.

```{r}
nlsy <- read.csv("http://www.andrew.cmu.edu/user/achoulde/94842/final_project/nlsy97_income/nlsy97_income.csv", header=TRUE, )

# Change column names (mostly) to question name abbreviations
# YOU MUST USE BETTER NAMES ON YOUR FINAL PROJECT!
# Change column names to question name abbreviations (you will want to change these further)
colnames(nlsy) <- c("INCARC_TOTNUM_XRND",
    "INCARC_AGE_FIRST_XRND",
    "INCARC_LENGTH_LONGEST_XRND",
    "PUBID_1997",
    "YSCH-36400_1997",
    "YSCH-37000_1997",
    "YSAQ-010_1997",
    "YEXP-300_1997",
    "YEXP-1500_1997",
    "YEXP-1600_1997",
    "YEXP-1800_1997",
    "YEXP-2000_1997",
    "gender",
    "KEY_BDATE_M_1997",
    "KEY_BDATE_Y_1997",
    "PC9-002_1997",
    "PC12-024_1997",
    "PC12-028_1997",
    "CV_BIO_MOM_AGE_CHILD1_1997",
    "CV_BIO_MOM_AGE_YOUTH_1997",
    "CV_ENROLLSTAT_1997",
    "CV_HH_NET_WORTH_P_1997",
    "CV_SAMPLE_TYPE_1997",
    "CV_HGC_RES_DAD_1997",
    "CV_HGC_RES_MOM_1997",
    "race",
    "FP_YMFRELAT_1997",
    "FP_YFMRELAT_1997",
    "YSCH-6800_1998",
    "YSCH-7300_1998",
    "YSAQ-372B_1998",
    "FP_YMFRELAT_1998",
    "FP_YFMRELAT_1998",
    "YSAQ-371_2000",
    "YSAQ-282J_2002",
    "YSAQ-282Q_2002",
    "CV_HH_NET_WORTH_Y_2003",
    "CV_BIO_CHILD_HH_2003",
    "weight",
    "YSAQ-373_2004",
    "YSAQ2-292_2005",
    "YTEL-52~000001_2007",
    "YTEL-52~000002_2007",
    "YTEL-52~000003_2007",
    "YTEL-52~000004_2007",
    "CV_BIO_CHILD_HH_2010",
    "CV_COLLEGE_TYPE.01_2011",
    "CV_INCOME_FAMILY_2011",
    "CV_HH_SIZE_2011",
    "CV_HH_UNDER_18_2011",
    "CV_HH_UNDER_6_2011",
    "CV_HIGHEST_DEGREE_1112_2011",
    "YSCH-3112_2011",
    "YSAQ-000A000001_2011",
    "YSAQ-000A000002_2011",
    "YSAQ-000B_2011",
    "YSAQ-360C_2011",
    "YSAQ-364D_2011",
    "YSAQ-371_2011",
    "YSAQ-372CC_2011",
    "YSAQ-373_2011",
    "YSAQ-374_2011",
    "YHEA29-285_2011",
    "YEMP_INDCODE-2002.01_2011",
    "VERSION_R16_2013",
    "YINC_1400_2013",
    "income",
    "YINC_1800_2013",
    "YINC_2400_2013",
    "YINC_2600_2013",
    "YINC_2700_2013",
    "CVC_SAT_MATH_SCORE_2007_XRND",
    "CVC_SAT_VERBAL_SCORE_2007_XRND",
    "CVC_ACT_SCORE_2007_XRND",
    "CVC_ASSETS_DEBTS_20_XRND",
    "CVC_TTL_JOB_TEEN_XRND",
    "CVC_TTL_JOB_ADULT_ET_XRND",
    "CVC_TTL_JOB_ADULT_ALL_XRND",
    "CVC_ASSETS_DEBTS_30_XRND")

# Map all negative values to missing (NA)
# DO NOT DO THIS IN YOUR PROJECT WITHOUT CAREFUL JUSTIFICATION
nlsy[nlsy < 0] <- NA
```

#### **(a)** Run a linear regression modeling `income` as a linear function of `gender`, `race` and `weight`.

```{r}
# Transform and relabel gender and race variables

```{r}

nlsy <- transform(nlsy, 
                  gender = mapvalues(gender, c(1, 2), c("male", "female")),
                  race = mapvalues(race, 1:4, c("Black", "Hispanic", "Mixed", "Other"))
                  )
```

**Note**: As a first step, you should convert `gender` and `race` to factors.

```{r}
# Run regression
nlsy.lm <- lm(income ~ gender + race + weight, data = nlsy)

# Output summary
summary(nlsy.lm)
```

#### **(d)** Use the `anova()` function to assess whether race is a statistically significant predictor of income by comparing your model from part (a) to a model with just `gender` and `weight`. 

**Hint**: You can use the `update()` function to drop predictors from a model.

```{r}
anova(update(nlsy.lm, . ~ . - race), nlsy.lm)
```

Race turns out to be a highly statistically signficant predictor of income in the model.  You can see also by looking at the coefficient estimates and standard errors --- the estimated coefficients are very large, with relatively small standard errors.

#### **(e)**  Update your linear regression model from part (a) to also include an interaction term between `race` and `gender`.

```{r}
nlsy.lm.interact <- update(nlsy.lm, . ~ . + race*gender)

summary(nlsy.lm.interact)
```

#### **(f)** How many coefficients are estimated for this interaction term?

There are 3 estimated coefficients.

#### **(g)** What do you think these coefficients mean?  How would you interpret them?  

```{r}
coef.race.mixed <- round(coef(nlsy.lm.interact)["gendermale:raceMixed"], 0)

coef.race.mixed
```

These coefficients correspond to differences in earnings across gender and race that aren't accounted for by a model that assumes independent effects for race and gender.  That is, the income difference between men and women appears to depend strongly on the individual's race.  For instance, the income difference among mixed-race men and mixed-race women is $`r coef.race.mixed` more than the difference between black men and black women.  Race is a factor that is highly associated with the income gap between men and women.

**Note**: This is different from saying that race is associated with income.  The interaction terms are estimates of how the **income gap** differs across the race categories.

#### Main effects vs. interactions

The final project asks you to explore the question of whether there are any factors that exacerbate or mitigate the **income gap** between men and women.  It's important to note that this is different from asking whether there are factors that affect income.  While it is interesting to investigate factors that affect income, there may be factors that affect income but do not affect the income gap.  This is the difference between significant main effects and significant interactions.

Let's look at the two linear models again.

```{r, results = 'asis'}
# Note how digits is specified here to round each column to a different number of decimal values
kable(coef(summary(nlsy.lm)), digits = c(0, 0, 2, 4))
```

```{r, results = 'asis'}
kable(coef(summary(nlsy.lm.interact)), digits = c(0, 0, 2, 4))
```

According to the first model, the average income difference between a 160lb Hispanic male and a 160lb Hispanic female is just:

Estimated.income(Male, Hispanic, 160lb) - Estimated.income(Female, Hispanic, 160lb)

 = ( `(Intercept)` + `gendermale` + `raceHispanic` + 160 * `weight`) - 
 (`(Intercept)` + `raceHispanic` + 160 * `weight`)
 
 = `gendermale`
 
 = `r round(coef(nlsy.lm)["gendermale"], 0)`
 
 Indeed, this is the average difference in income between men and women of the same weight and same race, regardless of their specific weight and race.
 
 
 According to the second model, the one that contains race-gender interactions, the average difference between the same two individuals is given by:
 
 Estimated.income(Male, Hispanic, 160lb) - Estimated.income(Female, Hispanic, 160lb)
 
  = ( `(Intercept)` + `gendermale` + `raceHispanic` + 160 * `weight` + `gendermale:raceHispanic`) - 
 (`(Intercept)` + `raceHispanic` + 160 * `weight`)
 
 = `gendermale` + `gendermale:raceHispanic`
 
 = `r round(coef(nlsy.lm.interact)["gendermale"], 0) + round(coef(nlsy.lm.interact)["gendermale:raceHispanic"], 0)`
 
 This difference doesn't depend on the weight of the individuals---we would get the same difference if we assumed that we had a man and woman both weighing 175lb---but it **does depend on the assumed race**.  Running the same calculation to compare a mixed race man and a mixed race woman of the same weight, we would get that the average income difference is:
 
 Estimated.income(Male, Mixed, xxxlb) - Estimated.income(Female, Mixed, xxxlb) 
 
 = `gendermale` + `gendermale:raceMixed`
 
 = `r round(coef(nlsy.lm.interact)["gendermale"], 0) + round(coef(nlsy.lm.interact)["gendermale:raceMixed"], 0)`
 
 
 The baseline level here is race = 'Black'.  So the model also tells us that the average income difference between Black men and women of the same weight is:
 
  Estimated.income(Male, Black, xxxlb) - Estimated.income(Female, Black, xxxlb) 
 
 = `gendermale` + 0
 
 = `r round(coef(nlsy.lm.interact)["gendermale"], 0)`
 
 By looking at the interaction effect between `race` and `gender`, we do find evidence that race is a factor affecting the **income gap** between men and women.  E.g., There is a significantly larger gap (in an absolute $ sense) between Hispanic men and women race compared to Black men and women.  Note that even though `gendermale:raceMixed` is larger than `gendermale:raceHispanic`, the former is not statistically significant, so we should be cautious about overemphasizing the large size of the coefficient. 
 
#### Testing significance of the interacton term with `anova`

By looking at the individual p-values for the interaction term coefficients, we can answer the question of whether the difference in income gap differs between Black individuals and those of a different given race category.  To more directly answer the question of whether the observed differences in income gap across the race categories are statistically significant, we need to use the `anova` command.

```{r}
anova(nlsy.lm, nlsy.lm.interact)
```
 
The p-value is statistically significant, so we can reject the null hypothesis that the income gap is the same across all the race categories.  In other words, the data suggests that the income gap between men and women does vary with race.  
 
#### The regression-free approach

In the previous examples we used a regression because we wanted to adjust for the `weight` variable.  However, before delving into a regression, you can get a lot of the same insights with some simple plots and tables.  

Here's a `ddply()` call that calculated the difference in average income between men and women for each race category.

```{r}
ddply(nlsy, ~ race, summarize, 
      income.gap = mean(income[gender == "male"], na.rm = TRUE) - mean(income[gender == "female"], na.rm = TRUE))
```

This is a great, easy-to-interpret table that you can include in your analysis.  By changing out `race` for other categorical variables, you can try to identify other factors that may affect the income gap.

Here's a one-line plotting command that summarizes the previous table in an east-to-interpret plot.

```{r, fig.width = 5}
gap.data <- ddply(nlsy, ~ race, summarize, 
                  income.gap = mean(income[gender == "male"], na.rm = TRUE) - mean(income[gender == "female"], na.rm = TRUE))

ggplot(data = gap.data, aes(x = race, y = income.gap, fill = race)) +
  geom_bar(stat = "identity") +
  xlab("Race") + 
  ylab("Income gap($)") +
  ggtitle("Income gap between men and women, by race") + 
  guides(fill = FALSE)
```

To really complete the graphic, you could consider the following two additions:

1) Re-order the variables on the x axis so that the bars are sorted by height.  i.e., plot the bars in ascending or descending order of wage gap.

2) By running t-tests you can obtain confidence intervals for the income gaps.  You can plot these using the `geom_errorbar` layer in ggplot.  

#### Improving the figure

##### Step 1: Reordering the bars

This is a simple matter of reordering the `race` variable in the `gap.data` data frame according to the value of `income.gap`.  The plotting command itself remains unchanged.

```{r, fig.width = 5}
# Reorder race factor levels according to income.gap
gap.data <- transform(gap.data,
                      race = reorder(race, income.gap))

# Same plotting command as before
ggplot(data = gap.data, aes(x = race, y = income.gap, fill = race)) +
  geom_bar(stat = "identity") +
  xlab("Race") + 
  ylab("Income gap($)") +
  ggtitle("Income gap between men and women, by race") + 
  guides(fill = FALSE)
```

**Note**: This changes which bar color gets used for which race.  If race is used several times in your analysis, you probably don't want the mapping between colors and race to keep changing.  To address this, you may want to manually specify the color mapping, or just use a single color for all the bars in the above plot.  E.g.,

```{r, fig.width = 5}
ggplot(data = gap.data, aes(x = race, y = income.gap)) +
  geom_bar(stat = "identity", fill = I('#548696')) +
  xlab("Race") + 
  ylab("Income gap($)") +
  ggtitle("Income gap between men and women, by race") + 
  guides(fill = FALSE)
```

##### Step 2: Adding error bars using t-test confidence intervals

Now that we've introduced the plyr package, we can quite easily put together all the information we need in order to add error bars to our plot.  

First, note that when we run a t.test with formula `income ~ gender` the difference that's calculated is **female income - male income**.  We want **male income - female income**.  Thus when we get a confidence interval from the t-test, we want to flip it and change the sign.  i.e., if [-8000, -2000] is a 95% confidence interval for $\mu_F - \mu_M$, then [2000, 8000] is a  95% confidence interval for $\mu_M - \mu_F$.  This is what the code below does to calculate error bars for our plot.

```{r, fig.width = 5}
# Calculate income gaps (male - female) and 95% confidence intervals
# for the gap
gap.data.conf <- ddply(nlsy, ~ race, summarize, 
                       income.gap = mean(income[gender == "male"], na.rm = TRUE) - mean(income[gender == "female"], na.rm = TRUE),
                       upper = -t.test(income ~ gender)$conf.int[1],
                       lower = -t.test(income ~ gender)$conf.int[2],
                       is.significant = as.numeric(t.test(income ~ gender)$p.value < 0.05))

# Re-order the race factor according to gap size
gap.data.conf <- transform(gap.data.conf,
                           race = reorder(race, income.gap))

# Plot, with error bars
ggplot(data = gap.data.conf, aes(x = race, y = income.gap)) +
  geom_bar(stat = "identity", fill = I('#548696')) +
  xlab("Race") + 
  ylab("Income gap($)") +
  ggtitle("Income gap between men and women, by race") + 
  guides(fill = FALSE) +
  geom_errorbar(aes(ymax = upper, ymin = lower), width = 0.1, size = 1) +
  theme(text = element_text(size=12)) 
```

**Note**:  Even though the **estimated** income gap between men and women is largest among Mixed race individuals, there aren't many Mixed race respondents, and so our error bars are extremely wide.  We don't even have enough observations to reject the null in this group (null: Mixed race men and women on average have the same income).  

<br><br><br><br>

## plyr Basics

#### split-apply-combine


- We've already seen numerous examples of split-apply-combine in action

- The basic principle to keep in mind is as follows:

1. **Split** a data set into piece (e.g., according to some factor)

2. **Apply** a function to each piece (e.g., mean)

3. **Combine** all the pieces into a single output (e.g., a table or data frame)

#### What does plyr do?


plyr introduces a family of functions of the form `XYply`, where `X` specifies the input type and `Y` specifies the output type

<center>

|  X/Y option  |  Sepal.Width|  
|:------------:|:------------|
|       `a`    | array (e.g., vector or matrix) |
|       `d`    | data.frame |
|       `l`    | list       |
|       `_`    | no output (valid only for `Y`, useful when plotting) |


</center>

> **Usage:** `XYply(.data, .variables, .fun)`

> **Effect:** Take input of type `X`, and apply `.fun` to `.data` split up according to `.variables`, combining the answer into output of type `Y`


#### Gapminder life expectancy data


```{r}
gapminder <- read.delim("http://www.andrew.cmu.edu/user/achoulde/94842/data/gapminder_five_year.txt") # Load data
str(gapminder) # Get variable information
```
#### Example: GDP by continent

```{r}
#ddply
ddply(gapminder, ~ continent, summarize, 
      mean.gdp = mean(gdpPercap))
#daply
daply(gapminder, ~ continent, summarize, mean.gdp = mean(gdpPercap))
#dlply
dlply(gapminder, ~ continent, summarize, mean.gdp = mean(gdpPercap))
```

- `summarize()` tells plyr to create a new data.frame containing the output
- `transform()` works like the function you already know, appending the results to the existing data frame

Here's what happens if we use transform instead (only first 6 rows are printed).

When using `transform`, a new column is created.  This column gives the average GDP per capita for corresponding continent.  All countries on the same continent get the same value for the new column.  

```{r}
transform.gdp.continent <- ddply(gapminder, ~ continent, transform, mean.gdp = mean(gdpPercap))

# First few rows
head(transform.gdp.continent)

# Output subsetted to 4 countries and one year
subset(transform.gdp.continent, subset = country %in% c("United Kingdom", "Ireland", "United States", "Mexico") & year == 2007)
```

#### Example: calculate correlation between gdpPercap and population for each country

```{r}
ddply(gapminder, ~ country, summarize, 
      cor.pop.gdp = cor(pop, gdpPercap))
```

#### Example: plot gdpPercap and population for each country

```{r, cache=TRUE, fig.height = 3}
# Set things up so that there are 3 columns of plots
par(mfrow = c(1,3)) 

# Use d_ply to generate plots
d_ply(gapminder, ~ country, 
      summarize, 
      plot(pop, gdpPercap, pch=16, main = country[1]))
```

**Note**:  When specifying the title (`main`) in `plot()`, we needed to write `unique(country)` instead of `country`.  If we didn't put `unique(country)`, then the title would have the country repeated as many times as the country appears in the data set.

#### Example: Maximum life expectancy for each continent

You can return more than one thing, and you're not limited to summarizing one variable at a time.

Here's a `ddply` call that outputs a summary table showing the maximum life expectancy for each continent and year, along with the country with the maximum life expectancy.

```{r, cache = TRUE}
ddply(gapminder, ~ continent + year, 
      summarize, 
      max.life.exp = max(lifeExp), 
      max.life.exp.country = country[which.max(lifeExp)])
```

#### Example (more involved): Fitting a linear model for each country

We're now going to go through an example where we get a slope and intercept for regressing `lifeExp` on year.

##### (1) Build a function

Let's start by building our function for a single country.

```{r, fig.align='center', fig.height=4, fig.width=5}
country.name <- "Ireland"  # Pick a country
gapminder.sub <- subset(gapminder, country == country.name)  # Pull data for this country
gapminder.sub

# Scatterplot of life exp vs year
qplot(year, lifeExp, data = gapminder.sub, main = paste("Life expectancy in", country.name)) 
```

Now let's fit a regression.

```{r}
life.exp.lm <- lm(lifeExp ~ year, data = gapminder.sub) # Fit model
summary(life.exp.lm) # Get summary print-out for model
```

The intercept in this case corresponds to the expected life expectancy in the year 0 A.D.  This number makes no sense, because we're essentially taking data from 1952 - 2007 and linearly extrapolating it back nearly 2000 years.  

A better thing to do is to shift the year variable to measure number of years since 1952.  Here's how we do this.

```{r}
year.min <- min(gapminder$year)  # Earliest year in the data set
# Fit a linear model with year replaced by year - year.min
life.exp.lm <- lm(lifeExp ~ I(year - year.min), data = gapminder.sub)

summary(life.exp.lm)
```

This is much better!  The slope hasn't changed (it shouldn't), but the intercept is now the life expectancy predicted by the linear fit for 1952.  This is within our range of observations, and so the prediction is not absurd.

Now we can pull the coefficients vector:

```{r}
life.exp.lm$coef
```

Let's put this all together into a function

```{r}
# Function returns slope and intercept from regressing lifeExp on year - year.min
getCoef <- function(df) {
  coefs <- lm(lifeExp ~ I(year - year.min), data = df)$coef
  names(coefs) <- c("intercept", "slope")
  coefs
}

getCoef(gapminder.sub)
```

##### (2) ddply the function

```{r}
ddply(gapminder, ~ country, getCoef)
```

#### Another approach: dlply + ldply = ddply

Another approach you might want to take is to store each lm fit in an intermediate list that you can use later.  

##### Step (1): Get a list of lm fits, one for each country

To do this, we use the `dlply` function, which takes a data frame and outputs a list (in this case, a list of `lm` fits).

```{r}
lm.list <- dlply(gapminder, ~ country, 
                 function(df) lm(lifeExp ~ I(year - year.min), data = df))
```

```{r}
# First element is the linear model fit for the first country
names(lm.list)[1]
lm.list[[1]]
summary(lm.list[[1]])
```

##### Step (2): Apply appropriate function to each lm fit

Now we have a list of linear models that we can call `ldply()` on.  How do we get coefficients out of a linear model?  Here's one approach

```{r}
coefs <- coef(lm.list[[1]])  # Use the coef() function, same effect as lm.fit$coef
coefs
names(coefs) <- c("intercept", "slope")
coefs
```

Turning this into a function:

```{r}
# Input: lm object x, the output of a univariate regression 
# Output: vector of length 2, giving slope and intercept
getCoefsLM <- function(x) {
  coefs <- coef(x)
  names(coefs) <- c("intercept", "slope")
  coefs
}

# Confirm that it does the same thing as our code above
getCoefsLM(lm.list[[1]])
```

Here's the `ldply` call that takes the list of lm fits and outputs a table giving the intercept and slope for each country.

```{r}
ldply(lm.list, getCoefsLM)
```

#### What can we learn from this output?

Let's summarize our findings by creating a bar chart for the intercept and slope, with the bars colored by continent.  We'll do this in ggplot.

```{r}
# Coefficients summary data frame
summary.coef <- ddply(gapminder, ~ country, getCoef)
# data frame showing continent of each country
summary.continent <- ddply(gapminder, ~ country, summarize, continent = unique(continent))
# Merge data together
summary.merge <- merge(summary.coef, summary.continent, by = "country")
# Here are the first few lines
head(summary.merge)
```

#### Plotting intercepts coloured by continent

This code is analogous to that presented at the end of Lecture 6

```{r, fig.width = 18, warning = FALSE}
# Reorder the countries according to intercept
summary.intercept <- transform(summary.merge, country = reorder(country, intercept))
# Construct ggplot object, will fill color determined by continent
intercept.fig <- ggplot(data = summary.intercept, mapping = aes(x = country, y = intercept, fill = continent))
# Construct bar chart
intercept.fig + geom_bar(stat = "identity") +
               theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust = 1)) 
```

#### Plotting slopes coloured by continent

```{r, fig.width = 18, warning = FALSE}
# Reorder the countries according to intercept
summary.slope <- transform(summary.merge, country = reorder(country, slope))
# Construct ggplot object, will fill color determined by continent
slope.fig <- ggplot(data = summary.slope, mapping = aes(x = country, y = slope, fill = continent))
# Construct bar chart
slope.fig + geom_bar(stat = "identity") +
               theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust = 1)) 
```


These are very interesting plots.  What can you tell from looking at them?

#### Looking at per capita GDP by year

Let's start by looking at some plots of how GDP per capita varied by year 

```{r, fig.height = 20, fig.width = 15, cache = TRUE}
# Use qplot from ggplot2 to generate plots
qplot(year, gdpPercap, facets = ~ country, data = gapminder, colour = continent) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

What if we want to rearrange the plots by continent?   This can be done by changing the order of the `country` level.  

```{r, fig.height = 20, fig.width = 15, cache = TRUE}
# First step: reorder the countries by continent
# Produce a data frame of just country and continent
country.df <- ddply(gapminder, ~ country, 
                    function(df) data.frame(continent.id = df$continent[1]))
# Print out first few lines
head(country.df)
# Use arrange() to sort table by continent
country.ordered <- arrange(country.df, continent.id)
# Print out first few lines
head(country.ordered)
# Reorder levels of country:
gapminder.ordered <- transform(gapminder, country = factor(country, levels = country.ordered$country))
# Let's make sure that things are now ordered correctly...
levels(gapminder.ordered$country)

# Use qplot from ggplot2 to generate plots
qplot(year, gdpPercap, facets = ~ country, data = gapminder.ordered, colour = continent) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + stat_smooth(method = "lm") 
```